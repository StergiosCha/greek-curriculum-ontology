"""
COMPLETE FIXED Contradiction Detector with Full Progression Support and Name Validation
Handles all new ontology properties from enhanced extraction
"""

from typing import List, Dict, Any, Optional, Tuple
import logging
from pathlib import Path
import re
import json
import time
from rdflib import Graph, RDF, RDFS, URIRef, Namespace, Literal

from app.services.llm_service import MultiLLMService, LLMProvider

logger = logging.getLogger(__name__)

CURRICULUM = Namespace("http://curriculum.edu.gr/2022/")
CURRKG = Namespace("http://curriculum-kg.org/ontology/")

class ContradictionDetector:
    """Enhanced LLM-powered contradiction detector with FULL PROGRESSION SUPPORT and NAME VALIDATION"""
    
    def __init__(self):
        self.llm_service = MultiLLMService()
        self.grade_level_mappings = {
            'A_Dimotikou': 1, 'B_Dimotikou': 2, 'C_Dimotikou': 3,
            'D_Dimotikou': 4, 'E_Dimotikou': 5, 'ST_Dimotikou': 6,
            'A_Gymnasiou': 7, 'B_Gymnasiou': 8, 'C_Gymnasiou': 9,
            'A_Lykeiou': 10, 'B_Lykeiou': 11, 'C_Lykeiou': 12,
            'A Gymnasio': 7, 'B Gymnasio': 8, 'C Gymnasio': 9,
            'Î‘Î„ Î“Ï…Î¼Î½Î±ÏƒÎ¯Î¿Ï…': 7, 'Î’Î„ Î“Ï…Î¼Î½Î±ÏƒÎ¯Î¿Ï…': 8, 'Î“Î„ Î“Ï…Î¼Î½Î±ÏƒÎ¯Î¿Ï…': 9
        }
        
    def setup_llm(self, provider: LLMProvider, api_key: str):
        """Setup LLM for semantic analysis"""
        self.llm_service.add_service(provider, api_key)
    
    def load_ontology(self, file_path: Path) -> Graph:
        """Load RDF ontology from file"""
        g = Graph()
        try:
            g.parse(file_path, format="turtle")
            logger.info(f"Loaded ontology with {len(g)} triples from {file_path}")
            return g
        except Exception as e:
            logger.error(f"Error loading ontology {file_path}: {e}")
            return Graph()
    
    def _extract_actual_names(self, curriculum_content: Dict[str, Any]) -> Dict[str, List[str]]:
        """Extract actual module and outcome names for validation"""
        names = {
            'modules': [],
            'outcomes': [],
            'strategies': []
        }
        
        for module in curriculum_content.get('modules', []):
            if module.get('title'):
                full_name = module['title']
                if module.get('grade_level'):
                    full_name += f" ({module['grade_level']})"
                names['modules'].append(full_name)
        
        for outcome in curriculum_content.get('learning_outcomes', []):
            if outcome.get('text'):
                text = outcome['text'][:80]
                if outcome.get('grade_levels'):
                    text += f" ({', '.join(outcome['grade_levels'])})"
                names['outcomes'].append(text)
        
        for strategy in curriculum_content.get('assessment_strategies', []):
            if strategy.get('greek_term'):
                names['strategies'].append(strategy['greek_term'])
        
        return names
    
    def _validate_response_names(self, response: Dict[str, Any], actual_names: Dict[str, List[str]]) -> bool:
        """Validate that response uses actual names, not placeholders"""
        
        # Generic placeholders to detect
        generic_patterns = [
            r'Î•Î½ÏŒÏ„Î·Ï„Î± [Î‘Î’Î“Î”Î•Î–Î—Î˜Iabcdefghxyz]',
            r'Module [Î‘Î’Î“Î”Î•Î–Î—Î˜Iabcdefghxyz]',
            r'Î£Ï„ÏŒÏ‡Î¿Ï‚ \d+',
            r'ÎœÎ¬Î¸Î·Î¼Î± [Î‘Î’Î“Î”Î•Î–Î—Î˜Iabcdefghxyz]',
            r'Î ÏÏŒÎ³ÏÎ±Î¼Î¼Î± [Î‘Î’Î“Î”Î•Î–Î—Î˜Iabcdefghxyz]',
            r'element\d+',
            r'Lesson [Î‘Î’Î“Î”Î•Î–Î—Î˜Iabcdefghxyz]'
        ]
        
        # Check contradictions for generic names
        for contradiction in response.get('contradictions', []):
            description = contradiction.get('description', '')
            elements = contradiction.get('elements', [])
            
            # Check description and elements
            text_to_check = description + ' ' + ' '.join(elements)
            
            for pattern in generic_patterns:
                if re.search(pattern, text_to_check, re.IGNORECASE):
                    logger.warning(f"Found generic placeholder matching pattern: {pattern}")
                    return False
        
        return True

    def detect_internal_contradictions(self, ontology_path: Path, provider: LLMProvider) -> Dict[str, Any]:
        """Find contradictions within a single curriculum with PROGRESSION ANALYSIS"""
        g = self.load_ontology(ontology_path)
        
        # Extract curriculum content WITH PROGRESSION
        curriculum_content = self._extract_curriculum_content_with_progression(g)
        
        if not curriculum_content:
            return {'contradictions': [], 'analysis': 'No curriculum content found'}
        
        # Extract actual names for validation
        actual_names = self._extract_actual_names(curriculum_content)
        
        # Format for analysis
        formatted_content = self._format_curriculum_with_progression(curriculum_content)
        
        prompt = f"""âš ï¸âš ï¸âš ï¸ ÎšÎ¡Î™Î£Î™ÎœÎ— Î‘Î Î‘Î™Î¤Î—Î£Î— âš ï¸âš ï¸âš ï¸

Î˜Î‘ Î Î¡Î•Î Î•Î™ ÎÎ‘ Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î•Î¤Î• ÎœÎŸÎÎŸ Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ Î‘Î ÎŸ Î¤Î— Î›Î™Î£Î¤Î‘ Î Î‘Î¡Î‘ÎšÎ‘Î¤Î©!

Î”Î™Î‘Î˜Î•Î£Î™ÎœÎ‘ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘ Î•ÎÎŸÎ¤Î—Î¤Î©Î:
{chr(10).join(f"- {name}" for name in actual_names['modules'][:15])}

Î”Î™Î‘Î˜Î•Î£Î™ÎœÎ‘ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎœÎ‘Î˜Î—Î£Î™Î‘ÎšÎ‘ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘:
{chr(10).join(f"- {name[:100]}" for name in actual_names['outcomes'][:10])}

âš ï¸ Î‘Î ÎŸÎ›Î¥Î¤Î‘ Î‘Î Î‘Î“ÎŸÎ¡Î•Î¥ÎœÎ•ÎÎ‘ PLACEHOLDERS:
- "Î•Î½ÏŒÏ„Î·Ï„Î± Î‘", "Î•Î½ÏŒÏ„Î·Ï„Î± Î’", "Î•Î½ÏŒÏ„Î·Ï„Î± Î“"
- "Module A", "Module B"
- "Î£Ï„ÏŒÏ‡Î¿Ï‚ 1", "Î£Ï„ÏŒÏ‡Î¿Ï‚ 2"
- "ÎœÎ¬Î¸Î·Î¼Î± Î§", "Î ÏÏŒÎ³ÏÎ±Î¼Î¼Î± Î¨"
- ÎŸÏ€Î¿Î¹Î¿Î´Î®Ï€Î¿Ï„Îµ Î³ÎµÎ½Î¹ÎºÏŒ ÏŒÎ½Î¿Î¼Î±

Î‘Î½Î±Î»ÏÏƒÏ„Îµ Ï„Î¿ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿ ÎµÎ»Î»Î·Î½Î¹ÎºÎ¿Ï Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¿Ï Ï€ÏÎ¿Î³ÏÎ¬Î¼Î¼Î±Ï„Î¿Ï‚ Î³Î¹Î± ÎµÏƒÏ‰Ï„ÎµÏÎ¹ÎºÎ­Ï‚ Î±Î½Ï„Î¹Ï†Î¬ÏƒÎµÎ¹Ï‚ ÎšÎ‘Î™ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± Ï€ÏÎ¿ÏŒÎ´Î¿Ï…:

Î Î•Î¡Î™Î•Î§ÎŸÎœÎ•ÎÎŸ Î‘ÎÎ‘Î›Î¥Î¤Î™ÎšÎŸÎ¥ Î Î¡ÎŸÎ“Î¡Î‘ÎœÎœÎ‘Î¤ÎŸÎ£ ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ:
{formatted_content}

Î•ÎÎ¤ÎŸÎ Î™Î£Î¤Î• Î¤Î™Î£ Î‘ÎšÎŸÎ›ÎŸÎ¥Î˜Î•Î£ Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î™Î£:

1. ÎšÎ¥ÎšÎ›Î™ÎšÎ•Î£ Î Î¡ÎŸÎ‘Î Î‘Î™Î¤ÎŸÎ¥ÎœÎ•ÎÎ•Î£ Î“ÎÎ©Î£Î•Î™Î£:
   - Î•Î½ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Î· Î¼Î¯Î± Ï„Î·Î½ Î¬Î»Î»Î· ÎºÏ…ÎºÎ»Î¹ÎºÎ¬
   - Î ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î± Ï€Î¿Ï… Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¿ÏÎ½ Î±Î´Î¹Î­Î¾Î¿Î´Î±

2. Î Î¡ÎŸÎ’Î›Î—ÎœÎ‘Î¤Î‘ Î Î¡ÎŸÎŸÎ”ÎŸÎ¥:
   - Î›Î¬Î¸Î¿Ï‚ ÏƒÎµÎ¹ÏÎ¬ Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±Ï‚ (Ï€ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î¿ Ï€ÏÎ¹Î½ Î±Ï€ÏŒ Î²Î±ÏƒÎ¹ÎºÏŒ)
   - Î•Î»Î»ÎµÎ¯Ï€ÎµÎ¹Ï‚ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚
   - Î Î¿Î»Ï Î¼ÎµÎ³Î¬Î»Î± Î¬Î»Î¼Î±Ï„Î± Î´Ï…ÏƒÎºÎ¿Î»Î¯Î±Ï‚

3. Î‘Î£Î¥ÎÎ•Î Î•Î™Î•Î£ Î¥Î ÎŸÎ£Î¤Î—Î¡Î™ÎÎ—Î£:
   - ÎœÎ±Î¸Î·Ï„Î­Ï‚ Ï‡ÏÎµÎ¹Î¬Î¶Î¿Î½Ï„Î±Î¹ Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î±Î»Î»Î¬ Î´ÎµÎ½ Ï€Î±ÏÎ­Ï‡ÎµÏ„Î±Î¹
   - Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î´ÎµÎ½ Î¼ÎµÎ¹ÏÎ½ÎµÏ„Î±Î¹ Î¼Îµ Ï„Î·Î½ Ï€ÏÏŒÎ¿Î´Î¿

4. Î“ÎÎ©Î£Î¤Î™ÎšÎ•Î£ Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î™Î£:
   - Î Î±ÏÏŒÎ¼Î¿Î¹Î¿Î¹ ÏƒÏ„ÏŒÏ‡Î¿Î¹ Î¼Îµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¯Ï€ÎµÎ´Î±
   - Î‘ÏƒÏ…Î½Î­Ï€ÎµÎ¹ÎµÏ‚ ÏƒÏ„Î·Î½ Ï€Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î±

5. Î’Î‘Î˜ÎœÎ™Î”Î™ÎšÎ•Î£ Î‘Î£Î¥ÎÎ•Î Î•Î™Î•Î£:
   - Î¥Ï€ÎµÏÎ²Î¿Î»Î¹ÎºÎ¬ Î´ÏÏƒÎºÎ¿Î»ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± Ï„Î· Î²Î±Î¸Î¼Î¯Î´Î±
   - Î¥Ï€ÎµÏÎ²Î¿Î»Î¹ÎºÎ¬ ÎµÏÎºÎ¿Î»Î¿Î¹ ÏƒÏ„ÏŒÏ‡Î¿Î¹ Î³Î¹Î± Ï„Î· Î²Î±Î¸Î¼Î¯Î´Î±

Î¥Î ÎŸÎ§Î¡Î•Î©Î¤Î™ÎšÎ— ÎœÎŸÎ¡Î¦Î— Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£ (Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î©ÎÎ¤Î‘Î£ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘):

âŒ Î‘Î Î‘Î¡Î‘Î”Î•ÎšÎ¤ÎŸ Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘:
{{
  "contradictions": [
    {{
      "type": "prerequisite_loop",
      "description": "ÎšÏ…ÎºÎ»Î¹ÎºÎ® ÎµÎ¾Î¬ÏÏ„Î·ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½",
      "elements": ["Î•Î½ÏŒÏ„Î·Ï„Î± Î‘", "Î•Î½ÏŒÏ„Î·Ï„Î± Î’"]
    }}
  ]
}}

âœ… Î£Î©Î£Î¤ÎŸ Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘ (ÎœÎ• Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘):
{{
  "contradictions": [
    {{
      "type": "prerequisite_loop",
      "severity": "critical",
      "description": "Î— ÎµÎ½ÏŒÏ„Î·Ï„Î± 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î± ÎºÎ±Î¹ Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ® Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï' Î±Ï€Î±Î¹Ï„ÎµÎ¯ Ï‰Ï‚ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î¿ Ï„Î· 'ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î± Î›Î­Î¾ÎµÏ‰Î½ Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï', Î· Î¿Ï€Î¿Î¯Î± Î¼Îµ Ï„Î· ÏƒÎµÎ¹ÏÎ¬ Ï„Î·Ï‚ Î±Ï€Î±Î¹Ï„ÎµÎ¯ Ï„Î·Î½ 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î±' Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÏÎ½Ï„Î±Ï‚ ÎºÏ…ÎºÎ»Î¹ÎºÎ® ÎµÎ¾Î¬ÏÏ„Î·ÏƒÎ· Ï€Î¿Ï… ÎµÎ¼Ï€Î¿Î´Î¯Î¶ÎµÎ¹ Ï„Î· Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±",
      "elements": [
        "Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î± ÎºÎ±Î¹ Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ® (Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï)",
        "ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î± Î›Î­Î¾ÎµÏ‰Î½ (Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï)"
      ],
      "impact": "ÎŸÎ¹ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î´ÎµÎ½ Î¼Ï€Î¿ÏÎ¿ÏÎ½ Î½Î± Î¾ÎµÎºÎ¹Î½Î®ÏƒÎ¿Ï…Î½ ÎºÎ±Î¼Î¯Î± Î±Ï€ÏŒ Ï„Î¹Ï‚ Î´ÏÎ¿ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚ Ï‡Ï‰ÏÎ¯Ï‚ Î½Î± Î­Ï‡Î¿Ï…Î½ Î¿Î»Î¿ÎºÎ»Î·ÏÏÏƒÎµÎ¹ Ï„Î·Î½ Î¬Î»Î»Î·",
      "recommendation": "Î”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Ï„Î·Ï‚ 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î± ÎºÎ±Î¹ Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ®' ÏƒÎµ 'Î’Î±ÏƒÎ¹ÎºÎ® Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î±' (Ï‡Ï‰ÏÎ¯Ï‚ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î±) ÎºÎ±Î¹ 'Î ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î· Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ®' (Î¼ÎµÏ„Î¬ Ï„Î· ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î±)"
    }}
  ],
  "progression_quality": {{
    "overall_score": 7,
    "strengths": ["ÎšÎ±Î»Î¬ Î´Î¿Î¼Î·Î¼Î­Î½ÎµÏ‚ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚ ÏƒÏ„Î¿ Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï"],
    "weaknesses": ["ÎšÏ…ÎºÎ»Î¹ÎºÎ­Ï‚ ÎµÎ¾Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ„Î¿ Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï"]
  }},
  "overall_assessment": "Î¤Î¿ Ï€ÏÏŒÎ³ÏÎ±Î¼Î¼Î± Î­Ï‡ÎµÎ¹ ÎºÎ±Î»Î® Î´Î¿Î¼Î® Î±Î»Î»Î¬ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹ ÎµÏ€Î±Î½Î±ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ Ï„Ï‰Î½ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Ï‰Î½",
  "priority_fixes": ["Î•Ï€Î¯Î»Ï…ÏƒÎ· ÎºÏ…ÎºÎ»Î¹ÎºÎ®Ï‚ ÎµÎ¾Î¬ÏÏ„Î·ÏƒÎ·Ï‚ Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î±Ï‚-ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î±Ï‚"]
}}

Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÎµ JSON Î¼Î¿ÏÏ†Î®:
{{
  "contradictions": [
    {{
      "type": "prerequisite_loop|progression_error|support_inconsistency|cognitive_conflict|grade_misalignment",
      "severity": "critical|high|medium|low",
      "description": "Î›Î•Î Î¤ÎŸÎœÎ•Î¡Î—Î£ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ Î±Ï€ÏŒ Ï„Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿",
      "elements": ["Î‘ÎšÎ¡Î™Î’ÎŸ_ÎŸÎÎŸÎœÎ‘_Î•ÎÎŸÎ¤Î—Î¤Î‘Î£_1 (Î’Î‘Î˜ÎœÎ™Î”Î‘)", "Î‘ÎšÎ¡Î™Î’ÎŸ_ÎŸÎÎŸÎœÎ‘_Î•ÎÎŸÎ¤Î—Î¤Î‘Î£_2 (Î’Î‘Î˜ÎœÎ™Î”Î‘)"],
      "impact": "Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· ÎµÏ€Î¯Ï€Ï„Ï‰ÏƒÎ· ÏƒÏ„Î· Î¼Î¬Î¸Î·ÏƒÎ·",
      "recommendation": "Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Î»ÏÏƒÎ· Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘"
    }}
  ],
  "progression_quality": {{
    "overall_score": "1-10",
    "strengths": ["Î”Ï…Î½Î±Ï„Î¬ ÏƒÎ·Î¼ÎµÎ¯Î± Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘"],
    "weaknesses": ["Î‘Î´ÏÎ½Î±Î¼Î± ÏƒÎ·Î¼ÎµÎ¯Î± Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘"]
  }},
  "overall_assessment": "Î“ÎµÎ½Î¹ÎºÎ® Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·",
  "priority_fixes": ["Î•Ï€ÎµÎ¯Î³Î¿Ï…ÏƒÎµÏ‚ Î´Î¹Î¿ÏÎ¸ÏÏƒÎµÎ¹Ï‚ Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘"]
}}

ÎœÎŸÎÎŸ JSON - Î¤Î™Î ÎŸÎ¤Î‘ Î‘Î›Î›ÎŸ.
Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î¤Î• ÎœÎŸÎÎŸ Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ Î‘Î ÎŸ Î¤Î— Î›Î™Î£Î¤Î‘ Î ÎŸÎ¥ Î”ÎŸÎ˜Î—ÎšÎ•."""

        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = self.llm_service.generate_with_provider(provider, prompt)
                parsed_response = self._parse_llm_response(response)
                
                # Validate names
                if self._validate_response_names(parsed_response, actual_names):
                    logger.info(f"Response validation successful on attempt {attempt + 1}")
                    return parsed_response
                else:
                    logger.warning(f"Response validation failed on attempt {attempt + 1} - contains generic placeholders")
                    if attempt < max_retries - 1:
                        # Add stronger warning for retry
                        prompt = f"""Î Î¡ÎŸÎ—Î“ÎŸÎ¥ÎœÎ•ÎÎ— Î‘Î Î‘ÎÎ¤Î—Î£Î— Î‘Î ÎŸÎ¡Î¡Î™Î¦Î˜Î—ÎšÎ• - Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î‘Î¤Î• Î“Î•ÎÎ™ÎšÎ‘ PLACEHOLDERS!

Î˜Î‘ Î Î¡Î•Î Î•Î™ ÎÎ‘ Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î•Î¤Î• ÎœÎŸÎÎŸ Î‘Î¥Î¤Î‘ Î¤Î‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘:
{chr(10).join(f"âœ“ {name}" for name in actual_names['modules'][:20])}

""" + prompt
                        time.sleep(1)  # Brief pause before retry
                    
            except Exception as e:
                logger.error(f"LLM analysis failed on attempt {attempt + 1}: {e}")
                if attempt == max_retries - 1:
                    return {'error': str(e), 'contradictions': []}
        
        # If all retries failed validation
        logger.error("All retry attempts failed validation - returning with warning")
        parsed_response['validation_warning'] = "Response contains generic placeholders instead of actual names"
        return parsed_response
    
    def detect_cross_curriculum_contradictions(self, ontology_paths: List[Path], provider: LLMProvider) -> Dict[str, Any]:
        """Find contradictions between curricula WITH PROGRESSION ANALYSIS"""
        
        curricula_content = {}
        subject_relationships = {}
        all_actual_names = {}
        
        for path in ontology_paths:
            g = self.load_ontology(path)
            curriculum_data = self._extract_curriculum_content_with_progression(g)
            if curriculum_data:
                curricula_content[path.stem] = curriculum_data
                all_actual_names[path.stem] = self._extract_actual_names(curriculum_data)
                
                # Extract subject area and grade levels
                subject_area = self._infer_subject_area(curriculum_data['curriculum_title'])
                grade_levels = set()
                for module in curriculum_data.get('modules', []):
                    if module.get('grade_level'):
                        grade_levels.add(module['grade_level'])
                
                subject_relationships[path.stem] = {
                    'subject_area': subject_area,
                    'grade_levels': list(grade_levels),
                    'is_language_related': self._is_language_related_subject(subject_area, curriculum_data['curriculum_title'])
                }
        
        if len(curricula_content) < 2:
            return {'contradictions': [], 'analysis': 'Need at least 2 curricula for comparison'}
        
        return self._analyze_contradictions_with_progression(curricula_content, subject_relationships, provider, all_actual_names)
    
    def analyze_progression_coherence(self, ontology_paths: List[Path], provider: LLMProvider) -> Dict[str, Any]:
        """Analyze learning progression coherence WITH OUTCOME PROGRESSIONS"""
        
        # Group curricula by grade level WITH OUTCOME LINKS
        grade_curricula = {}
        outcome_progressions = {}
        all_actual_names = {}
        
        for path in ontology_paths:
            g = self.load_ontology(path)
            
            # Extract grade progression
            grade_info = self._extract_grade_progression_enhanced(g)
            if grade_info:
                grade_curricula[path.stem] = grade_info
            
            # Extract outcome progressions
            outcome_prog = self._extract_outcome_progressions(g)
            if outcome_prog:
                outcome_progressions[path.stem] = outcome_prog
            
            # Extract actual names
            curriculum_data = self._extract_curriculum_content_with_progression(g)
            if curriculum_data:
                all_actual_names[path.stem] = self._extract_actual_names(curriculum_data)
        
        if not grade_curricula:
            return {'analysis': 'No grade progression data found'}
        
        # Build names list for validation
        names_summary = "\n\nÎ”Î™Î‘Î˜Î•Î£Î™MA Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘:"
        for curriculum, names in all_actual_names.items():
            names_summary += f"\n\n{curriculum}:"
            names_summary += f"\n  Î•Î½ÏŒÏ„Î·Ï„ÎµÏ‚: {', '.join(names['modules'][:10])}"
        
        formatted_progression = ""
        for curriculum, grades in grade_curricula.items():
            formatted_progression += f"\n=== {curriculum} ===\n"
            for grade, content in grades.items():
                formatted_progression += f"Î’Î‘Î˜ÎœÎ™Î”Î‘ {grade}:\n{content}\n"
        
        # Add outcome progression data
        if outcome_progressions:
            formatted_progression += "\n\n=== Î Î¡ÎŸÎŸÎ”ÎŸÎ£ ÎœÎ‘Î˜Î—Î£Î™Î‘ÎšÎ©Î Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î ===\n"
            for curriculum, progressions in outcome_progressions.items():
                formatted_progression += f"\n{curriculum}:\n"
                for prog in progressions:
                    formatted_progression += f"  {prog['from']} â†’ {prog['to']} (Î•Ï€Î¯Ï€ÎµÎ´Î¿: {prog['level']})\n"
        
        prompt = f"""âš ï¸âš ï¸âš ï¸ Î¥Î ÎŸÎ§Î¡Î•Î©Î¤Î™ÎšÎ— Î§Î¡Î—Î£Î— Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ©Î ÎŸÎÎŸÎœÎ‘Î¤Î©Î âš ï¸âš ï¸âš ï¸

{names_summary}

Î‘Î½Î±Î»ÏÏƒÏ„Îµ Ï„Î·Î½ ÎµÎ¾ÎµÎ»Î¹ÎºÏ„Î¹ÎºÎ® ÏƒÏ…Î½Î¿Ï‡Î® Ï„Î·Ï‚ Î¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î¼Îµ Î Î›Î—Î¡Î— Î‘ÎÎ‘Î›Î¥Î£Î— Î Î¡ÎŸÎŸÎ”ÎŸÎ¥:

{formatted_progression}

Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î¤Î•:

1. Î›ÎŸÎ“Î™ÎšÎ— Î Î¡ÎŸÎŸÎ”ÎŸ:
   - ÎŸÎ¹ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï‡Ï„Î¯Î¶Î¿Î½Ï„Î±Î¹ Î¼ÎµÏ„Î±Î¾Ï Ï„Ï‰Î½ Î²Î±Î¸Î¼Î¯Î´Ï‰Î½;
   - Î¤Î± Î¼Î±Î¸Î·ÏƒÎ¹Î±ÎºÎ¬ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ¿ÏÎ½ Î»Î¿Î³Î¹ÎºÎ¬;
   - Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎºÎµÎ½Î¬ Î® Î¬Î»Î¼Î±Ï„Î± ÏƒÏ„Î· Î¼Î¬Î¸Î·ÏƒÎ·;

2. Î“ÎÎ©Î£Î¤Î™ÎšÎ— Î•ÎÎ•Î›Î™ÎÎ—:
   - Î¤Î± Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ¬ ÎµÏ€Î¯Ï€ÎµÎ´Î± Î±Ï…Î¾Î¬Î½Î¿Î½Ï„Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î±;
   - Î— Ï€Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î± Î±Ï…Î¾Î¬Î½ÎµÏ„Î±Î¹ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ¬;
   - Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î· Î²Î±Î¸Î¼Î¯Î´Ï‰ÏƒÎ· Î´Ï…ÏƒÎºÎ¿Î»Î¯Î±Ï‚;

3. Î Î¡ÎŸÎ‘Î Î‘Î™Î¤ÎŸÎ¥ÎœÎ•ÎÎ•Î£ Î“ÎÎ©Î£Î•Î™Î£:
   - ÎŸÎ¹ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ Î´Î¹Î´Î¬ÏƒÎºÎ¿Î½Ï„Î±Î¹ Ï€ÏÏÏ„Î±;
   - Î¤Î± Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î± Î¼ÎµÏ„Î±Î¾Ï ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ Î­Ï‡Î¿Ï…Î½ Î½ÏŒÎ·Î¼Î±;
   - Î¥Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÎ»Î»ÎµÎ¯Ï€ÎµÎ¹Ï‚ Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½ÎµÏ‚;

4. Î¥Î ÎŸÎ£Î¤Î—Î¡Î™ÎÎ— ÎœÎ‘Î˜Î—Î¤Î©Î:
   - Î— Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î· Î¼ÎµÎ¹ÏÎ½ÎµÏ„Î±Î¹ ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î± Î¼Îµ Ï„Î·Î½ Ï€ÏÏŒÎ¿Î´Î¿;
   - ÎŸÎ¹ Î¼Î±Î¸Î·Ï„Î­Ï‚ Î³Î¯Î½Î¿Î½Ï„Î±Î¹ ÏƒÏ„Î±Î´Î¹Î±ÎºÎ¬ Î±Î½ÎµÎ¾Î¬ÏÏ„Î·Ï„Î¿Î¹;

5. Î£Î¥ÎÎ•Î§Î•Î™Î‘ ÎœÎ‘Î˜Î—Î£Î—Î£:
   - Î¥Ï€Î¬ÏÏ‡ÎµÎ¹ Î¿Î¼Î±Î»Î® Î¼ÎµÏ„Î¬Î²Î±ÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Î²Î±Î¸Î¼Î¯Î´Ï‰Î½;
   - Î‘Ï€Î¿Ï†ÎµÏÎ³Î¿Î½Ï„Î±Î¹ ÎµÏ€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚ Ï‡Ï‰ÏÎ¯Ï‚ Î»ÏŒÎ³Î¿;

âš ï¸ Î‘Î Î‘Î“ÎŸÎ¡Î•Î¥ÎœÎ•ÎÎ‘ GENERICS:
âŒ "Î•Î½ÏŒÏ„Î·Ï„Î± Î‘", "ÎšÎµÎ½ÏŒ Î¼ÎµÏ„Î±Î¾Ï Î•Î½ÏŒÏ„Î·Ï„Î±Ï‚ Î‘ ÎºÎ±Î¹ Î’"
âŒ "Module X", "Î£Ï„ÏŒÏ‡Î¿Ï‚ 1"

âœ… Î¥Î ÎŸÎ§Î¡Î•Î©Î¤Î™ÎšÎ‘ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘:
"Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î± (Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï)", "Î£ÏÎ½Ï„Î±Î¾Î· (Î“' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï)"
"ÎšÎµÎ½ÏŒ Î¼ÎµÏ„Î±Î¾Ï 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î±' (Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï) ÎºÎ±Î¹ 'Î£ÏÎ½Ï„Î±Î¾Î·' (Î“' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï)"

Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘ Î£Î©Î£Î¤Î—Î£ Î‘Î Î‘ÎÎ¤Î—Î£Î—Î£:
{{
  "progression_analysis": {{
    "gaps": [
      "ÎšÎµÎ½ÏŒ Î¼ÎµÏ„Î±Î¾Ï 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î± ÎºÎ±Î¹ Î¦Ï‰Î½Î·Ï„Î¹ÎºÎ®' (Î‘' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï) ÎºÎ±Î¹ 'Î£ÏÎ½Ï„Î±Î¾Î· Î ÏÏŒÏ„Î±ÏƒÎ·Ï‚' (Î“' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï) - Î»ÎµÎ¯Ï€ÎµÎ¹ ÎµÎ½Î´Î¹Î¬Î¼ÎµÏƒÎ· ÎµÎ½ÏŒÏ„Î·Ï„Î± ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î±Ï‚"
    ],
    "overlaps": [
      "Î— 'Î’Î±ÏƒÎ¹ÎºÎ® Î“ÏÎ±Î¼Î¼Î±Ï„Î¹ÎºÎ®' (Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï) ÎºÎ±Î¹ 'Î•Î¹ÏƒÎ±Î³Ï‰Î³Î® ÏƒÏ„Î· Î£ÏÎ½Ï„Î±Î¾Î·' (Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï) Î´Î¹Î´Î¬ÏƒÎºÎ¿Ï…Î½ Ï„Î¿ Î¯Î´Î¹Î¿ Ï€ÎµÏÎ¹ÎµÏ‡ÏŒÎ¼ÎµÎ½Î¿"
    ]
  }},
  "grade_specific_issues": {{
    "Î“' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï": [
      "Î— 'Î£ÏÎ½Ï„Î±Î¾Î· Î ÏÏŒÏ„Î±ÏƒÎ·Ï‚' ÎµÎ¯Î½Î±Î¹ Ï€Î¿Î»Ï Ï€ÏÎ¿Ï‡Ï‰ÏÎ·Î¼Î­Î½Î· Ï‡Ï‰ÏÎ¯Ï‚ Ï„Î·Î½ ÎµÎ½Î´Î¹Î¬Î¼ÎµÏƒÎ· ÎµÎ½ÏŒÏ„Î·Ï„Î± 'ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î± Î›Î­Î¾ÎµÏ‰Î½' ÏƒÏ„Î¿ Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï"
    ]
  }},
  "recommendations": [
    "Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· ÎµÎ½ÏŒÏ„Î·Ï„Î±Ï‚ 'ÎœÎ¿ÏÏ†Î¿Î»Î¿Î³Î¯Î± Î›Î­Î¾ÎµÏ‰Î½' ÏƒÏ„Î¿ Î’' Î”Î·Î¼Î¿Ï„Î¹ÎºÎ¿Ï Î¼ÎµÏ„Î±Î¾Ï 'Î¦Ï‰Î½Î¿Î»Î¿Î³Î¯Î±' ÎºÎ±Î¹ 'Î£ÏÎ½Ï„Î±Î¾Î·'"
  ]
}}

Î‘Ï€Î±Î½Ï„Î®ÏƒÏ„Îµ ÏƒÎµ JSON Î¼Î¿ÏÏ†Î®:
{{
  "progression_analysis": {{
    "coherence_score": "Î²Î±Î¸Î¼ÏŒÏ‚_ÏƒÏ…Î½Î¿Ï‡Î®Ï‚_0_10",
    "logical_flow_score": "Î²Î±Î¸Î¼ÏŒÏ‚_Î»Î¿Î³Î¹ÎºÎ®Ï‚_ÏÎ¿Î®Ï‚_0_10",
    "gaps": ["ÎšÎµÎ½Î¬ Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ ÎºÎ±Î¹ Î²Î±Î¸Î¼Î¯Î´Ï‰Î½"],
    "overlaps": ["Î•Ï€Î±Î½Î±Î»Î®ÏˆÎµÎ¹Ï‚ Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½ ÎºÎ±Î¹ Î²Î±Î¸Î¼Î¯Î´Ï‰Î½"],
    "logical_flow": "Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·_Î»Î¿Î³Î¹ÎºÎ®Ï‚_ÏÎ¿Î®Ï‚",
    "cognitive_progression": "Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·_Î³Î½Ï‰ÏƒÏ„Î¹ÎºÎ®Ï‚_ÎµÎ¾Î­Î»Î¹Î¾Î·Ï‚",
    "prerequisite_alignment": "Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·_Ï€ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Ï‰Î½",
    "support_scaffolding": "Î±Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·_Ï…Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚"
  }},
  "grade_specific_issues": {{
    "ÎŸÎÎŸÎœÎ‘_Î’Î‘Î˜ÎœÎ™Î”Î‘Î£": ["Î˜Î­Î¼Î±Ï„Î± Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½"]
  }},
  "recommendations": ["Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ ÎµÎ½Î¿Ï„Î®Ï„Ï‰Î½"],
  "restructuring_needed": ["Î ÎµÏÎ¹Î¿Ï‡Î­Ï‚ Î¼Îµ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘"]
}}

Î§Î¡Î—Î£Î™ÎœÎŸÎ ÎŸÎ™Î—Î£Î¤Î• ÎœÎŸÎÎŸ Î¤Î‘ Î‘ÎšÎ¡Î™Î’Î— ÎŸÎÎŸÎœÎ‘Î¤Î‘ Î‘Î ÎŸ Î¤Î— Î›Î™Î£Î¤Î‘ Î Î‘Î¡Î‘Î Î‘ÎÎ©."""

        try:
            response = self.llm_service.generate_with_provider(provider, prompt)
            parsed = self._parse_llm_response(response)
            
            # Validate names in response
            has_generics = False
            for names in all_actual_names.values():
                if not self._validate_response_names(parsed, names):
                    has_generics = True
                    break
            
            if has_generics:
                parsed['validation_warning'] = "Response may contain generic placeholders"
            
            return parsed
        except Exception as e:
            logger.error(f"Progression analysis failed: {e}")
            return {'error': str(e)}

    def _is_hierarchical_parent_child(self, module1_title: str, module2_title: str) -> bool:
        """Check if two modules have parent-child relationship"""
        pattern = r'^(\d+(?:\.\d+)*)\.\s+'
        match1 = re.match(pattern, module1_title)
        match2 = re.match(pattern, module2_title)
        
        if not match1 or not match2:
            return False
        
        num1 = match1.group(1)
        num2 = match2.group(1)
        
        if num2.startswith(num1 + ".") or num1.startswith(num2 + "."):
            return True
        return False


    def _is_umbrella_module(self, module_title: str, module_topics: List[str]) -> bool:
        """Detect umbrella/overview modules"""
        umbrella_indicators = [
            'Î¸ÎµÏ‰ÏÎ·Ï„Î¹Îº', 'theoretical', 'ÎµÎ¹ÏƒÎ±Î³Ï‰Î³', 'introduction',
            'Î³ÎµÎ½Î¹Îº', 'general', 'Ï€Î»Î±Î¯ÏƒÎ¹Î¿', 'framework',
            'Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ·', 'approach', 'ÎµÏ€Î¹ÏƒÎºÏŒÏ€Î·ÏƒÎ·', 'overview'
        ]
        
        title_lower = module_title.lower()
        if any(ind in title_lower for ind in umbrella_indicators):
            return True
        
        if re.match(r'^1\.\s+', module_title) and len(module_topics) > 5:
            return True
        
        return False


    def _extract_module_metadata_with_structure(self, modules: List[Dict]) -> List[Dict]:
        """Add hierarchical structure metadata"""
        enhanced = []
        
        for module in modules:
            enh = module.copy()
            title = module.get('title', '')
            topics = module.get('topics', [])
            
            enh['is_umbrella'] = self._is_umbrella_module(title, topics)
            
            match = re.match(r'^(\d+(?:\.\d+)*)\.\s+', title)
            if match:
                enh['numbering'] = match.group(1)
                enh['depth'] = len(match.group(1).split('.'))
            else:
                enh['numbering'] = None
                enh['depth'] = 0
            
            enh['children'] = []
            enh['parent'] = None
            
            for other in modules:
                other_title = other.get('title', '')
                if self._is_hierarchical_parent_child(title, other_title):
                    if enh.get('numbering') and other_title.startswith(enh['numbering'] + '.'):
                        enh['children'].append(other_title)
                    else:
                        enh['parent'] = other_title
            
            enhanced.append(enh)
        
        return enhanced
    def _extract_curriculum_content_with_progression(self, g: Graph) -> Dict[str, Any]:
        """Extract curriculum content WITH ALL PROGRESSION DATA"""
        
        # Get curriculum name/title
        curriculum_title = ""
        for subj, pred, obj in g.triples((None, CURRKG.hasTitle, None)):
            if "Curriculum" in str(subj):
                curriculum_title = str(obj)
                break
        
        # Extract modules with FULL PROGRESSION
        modules = []
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.Module)):
            
            # Get prerequisites
            prerequisites = []
            for _, _, prereq_uri in g.triples((subj, CURRKG.hasPrerequisite, None)):
                prereq_title = self._get_property_value(g, prereq_uri, "hasTitle")
                if prereq_title:
                    prerequisites.append(prereq_title)
            
            # Get progression level
            progression_level = ""
            for _, _, prog_uri in g.triples((subj, CURRKG.hasProgressionLevel, None)):
                progression_level = str(prog_uri).split('/')[-1].replace('currkg:', '')
            
            # Get complexity indicators
            cognitive_level = ""
            independence_level = ""
            for _, _, cog_uri in g.triples((subj, CURRKG.cognitiveLevel, None)):
                cognitive_level = str(cog_uri).split('/')[-1].replace('currkg:', '')
            for _, _, ind_uri in g.triples((subj, CURRKG.independenceLevel, None)):
                independence_level = str(ind_uri).split('/')[-1].replace('currkg:', '')
            
            module_data = {
                'uri': str(subj),
                'title': self._get_property_value(g, subj, "hasTitle"),
                'description': self._get_property_value(g, subj, "hasDescription"),
                'grade_level': self._get_property_value(g, subj, "hasGradeLevel"),
                'progression_level': progression_level,
                'cognitive_level': cognitive_level,
                'independence_level': independence_level,
                'topics': self._get_all_topic_descriptions(g, subj),
                'prerequisites': prerequisites,
                'level': self._get_property_value(g, subj, "hasLevel"),
                'category': self._get_property_value(g, subj, "belongsTo"),
                'curriculum_title': curriculum_title  # Add curriculum title to each module
            }
            modules.append(module_data)
        
        # CRITICAL FIX: Sort modules by URI number to preserve document order
        # RDF graphs don't guarantee order, so we must sort explicitly
        def get_module_number(module):
            """Extract module number from URI like 'currkg:Module_1' """
            uri = module.get('uri', '')
            match = re.search(r'Module_(\d+)', uri)
            return int(match.group(1)) if match else 999
        
        modules.sort(key=get_module_number)
        logger.info(f"Extracted and sorted {len(modules)} modules by URI number")
        if modules:
            logger.info(f"Module order: {[m.get('title', 'Unknown')[:40] for m in modules[:5]]}")
        
        # Extract learning outcomes WITH PROGRESSION
        learning_outcomes = []
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.LearningOutcome)):
            
            # Get progression level
            progression_level = ""
            for _, _, prog_uri in g.triples((subj, CURRKG.progressionLevel, None)):
                progression_level = str(prog_uri).split('/')[-1].replace('currkg:', '')
            
            # Get support level
            support_level = ""
            for _, _, supp_uri in g.triples((subj, CURRKG.supportLevel, None)):
                support_level = str(supp_uri).split('/')[-1].replace('currkg:', '')
            
            # Get bloom level
            bloom_level = ""
            for _, _, bloom_uri in g.triples((subj, CURRKG.bloomLevel, None)):
                bloom_level = str(bloom_uri).split('/')[-1].replace('currkg:', '')
            
            # Get skill category
            skill_category = ""
            for _, _, skill_uri in g.triples((subj, CURRKG.skillCategory, None)):
                skill_category = str(skill_uri).split('/')[-1].replace('currkg:', '')
            
            # Get grades
            grades = []
            for _, _, grade_uri in g.triples((subj, CURRKG.applicableToGrade, None)):
                grade = str(grade_uri).split('/')[-1].replace('currkg:', '')
                grades.append(grade)
            
            # Get progressions to other outcomes
            progresses_to = []
            for _, _, target_uri in g.triples((subj, CURRKG.progressesTo, None)):
                progresses_to.append(str(target_uri))
            
            outcome_data = {
                'uri': str(subj),
                'text': self._get_property_value(g, subj, "hasText"),
                'grade_levels': grades,
                'progression_level': progression_level,
                'support_level': support_level,
                'bloom_level': bloom_level,
                'skill_category': skill_category,
                'progresses_to': progresses_to
            }
            learning_outcomes.append(outcome_data)
        
        # Extract assessment strategies WITH PROGRESSION
        assessment_strategies = []
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.AssessmentStrategy)):
            
            # Get assessment progression
            assessment_prog = ""
            for _, _, prog_uri in g.triples((subj, CURRKG.assessmentProgression, None)):
                assessment_prog = str(prog_uri).split('/')[-1].replace('currkg:', '')
            
            # Get complexity level
            complexity = ""
            for _, _, comp_uri in g.triples((subj, CURRKG.complexityLevel, None)):
                complexity = str(comp_uri).split('/')[-1].replace('currkg:', '')
            
            strategy_data = {
                'uri': str(subj),
                'type': self._get_property_value(g, subj, "strategyType"),
                'greek_term': self._get_property_value(g, subj, "greekTerm"),
                'complexity_level': complexity,
                'assessment_progression': assessment_prog,
                'progression_notes': self._get_property_value(g, subj, "progressionNotes")
            }
            assessment_strategies.append(strategy_data)
        
        # Extract teaching strategies WITH PROGRESSION
        teaching_strategies = []
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.TeachingStrategy)):
            
            # Get scaffolding type
            scaffolding = ""
            for _, _, scaff_uri in g.triples((subj, CURRKG.scaffoldingType, None)):
                scaffolding = str(scaff_uri).split('/')[-1].replace('currkg:', '')
            
            # Get teaching stage
            teaching_stage = ""
            for _, _, stage_uri in g.triples((subj, CURRKG.teachingStage, None)):
                teaching_stage = str(stage_uri).split('/')[-1].replace('currkg:', '')
            
            strategy_data = {
                'uri': str(subj),
                'name': self._get_property_value(g, subj, "strategyName"),
                'scaffolding_type': scaffolding,
                'teaching_stage': teaching_stage,
                'progression_notes': self._get_property_value(g, subj, "progressionNotes")
            }
            teaching_strategies.append(strategy_data)
        
        return {
            'curriculum_title': curriculum_title,
            'modules': modules,
            'learning_outcomes': learning_outcomes,
            'assessment_strategies': assessment_strategies,
            'teaching_strategies': teaching_strategies
        }
    def _extract_module_order_from_ontology(self, g: Graph) -> Dict[str, int]:
        """Extract module order from URI numbers (Module_1, Module_2, etc.)"""
        module_order = {}
        
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.Module)):
            uri_str = str(subj)
            # Extract number from URI like "currkg:Module_1"
            match = re.search(r'Module_(\d+)', uri_str)
            if match:
                module_number = int(match.group(1))
                module_title = self._get_property_value(g, subj, "hasTitle")
                if module_title:
                    module_order[module_title] = module_number
        
        return module_order
    def _extract_outcome_progressions(self, g: Graph) -> List[Dict[str, str]]:
        """Extract outcome progression relationships"""
        progressions = []
        
        for source, pred, target in g.triples((None, CURRKG.progressesTo, None)):
            source_text = self._get_property_value(g, source, "hasText")
            target_text = self._get_property_value(g, target, "hasText")
            
            source_level = ""
            for _, _, level_uri in g.triples((source, CURRKG.progressionLevel, None)):
                source_level = str(level_uri).split('/')[-1]
            
            if source_text and target_text:
                progressions.append({
                    'from': source_text[:100] + "..." if len(source_text) > 100 else source_text,
                    'to': target_text[:100] + "..." if len(target_text) > 100 else target_text,
                    'level': source_level
                })
        
        return progressions
    
    def _extract_grade_progression_enhanced(self, g: Graph) -> Dict[str, str]:
        """Extract grade-level progression WITH COMPLEXITY INFO"""
        grades = {}
        
        for subj, pred, obj in g.triples((None, RDF.type, CURRKG.Module)):
            grade_level = self._get_property_value(g, subj, "hasGradeLevel")
            if grade_level:
                module_title = self._get_property_value(g, subj, "hasTitle")
                module_desc = self._get_property_value(g, subj, "hasDescription")
                
                # Get progression info
                progression_level = ""
                for _, _, prog_uri in g.triples((subj, CURRKG.hasProgressionLevel, None)):
                    progression_level = str(prog_uri).split('/')[-1]
                
                cognitive_level = ""
                for _, _, cog_uri in g.triples((subj, CURRKG.cognitiveLevel, None)):
                    cognitive_level = str(cog_uri).split('/')[-1]
                
                if grade_level not in grades:
                    grades[grade_level] = []
                
                content = f"Î•Î½ÏŒÏ„Î·Ï„Î±: {module_title}"
                if module_desc:
                    content += f" - {module_desc}"
                if progression_level:
                    content += f" [Î ÏÏŒÎ¿Î´Î¿Ï‚: {progression_level}]"
                if cognitive_level:
                    content += f" [Î“Î½Ï‰ÏƒÏ„Î¹ÎºÏŒ: {cognitive_level}]"
                
                grades[grade_level].append(content)
        
        # Format for LLM
        formatted_grades = {}
        for grade, content_list in grades.items():
            formatted_grades[grade] = '\n'.join(content_list)
        
        return formatted_grades
    
    def _format_curriculum_with_progression(self, curriculum_data: Dict[str, Any]) -> str:
        """Format curriculum data WITH ALL PROGRESSION INFO"""
        
        formatted = f"Î¤Î™Î¤Î›ÎŸÎ£: {curriculum_data['curriculum_title']}\n\n"
        
        formatted += "=" * 80 + "\n"
        formatted += "Î•ÎÎŸÎ¤Î—Î¤Î•Î£ ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ:\n"
        formatted += "=" * 80 + "\n"
        for i, module in enumerate(curriculum_data['modules'], 1):
            formatted += f"\n{i}. {module['title']}\n"
            if module['description']:
                formatted += f"   Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®: {module['description']}\n"
            if module['grade_level']:
                formatted += f"   Î’Î±Î¸Î¼Î¯Î´Î±: {module['grade_level']}\n"
            if module['progression_level']:
                formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î ÏÎ¿ÏŒÎ´Î¿Ï…: {module['progression_level']}\n"
            if module['cognitive_level']:
                formatted += f"   Î“Î½Ï‰ÏƒÏ„Î¹ÎºÏŒ Î•Ï€Î¯Ï€ÎµÎ´Î¿: {module['cognitive_level']}\n"
            if module['independence_level']:
                formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î‘Î½ÎµÎ¾Î±ÏÏ„Î·ÏƒÎ¯Î±Ï‚: {module['independence_level']}\n"
            if module['level']:
                formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿: {module['level']}\n"
            if module['topics']:
                formatted += f"   Î˜Î­Î¼Î±Ï„Î±: {', '.join(module['topics'][:5])}\n"
            if module['prerequisites']:
                formatted += f"   Î ÏÎ¿Î±Ï€Î±Î¹Ï„Î¿ÏÎ¼ÎµÎ½Î±: {', '.join(module['prerequisites'])}\n"
            formatted += "\n"
        
        if curriculum_data.get('learning_outcomes'):
            formatted += "\n" + "=" * 80 + "\n"
            formatted += "ÎœÎ‘Î˜Î—Î£Î™Î‘ÎšÎ‘ Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î‘ ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ:\n"
            formatted += "=" * 80 + "\n"
            for i, outcome in enumerate(curriculum_data['learning_outcomes'], 1):
                formatted += f"\n{i}. {outcome['text'][:150]}...\n" if len(outcome['text']) > 150 else f"\n{i}. {outcome['text']}\n"
                if outcome['grade_levels']:
                    formatted += f"   Î’Î±Î¸Î¼Î¯Î´ÎµÏ‚: {', '.join(outcome['grade_levels'])}\n"
                if outcome['progression_level']:
                    formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î ÏÎ¿ÏŒÎ´Î¿Ï…: {outcome['progression_level']}\n"
                if outcome['support_level']:
                    formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚: {outcome['support_level']}\n"
                if outcome['bloom_level']:
                    formatted += f"   Bloom Î•Ï€Î¯Ï€ÎµÎ´Î¿: {outcome['bloom_level']}\n"
                if outcome['skill_category']:
                    formatted += f"   ÎšÎ±Ï„Î·Î³Î¿ÏÎ¯Î± Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„Î±Ï‚: {outcome['skill_category']}\n"
                if outcome['progresses_to']:
                    formatted += f"   Î ÏÎ¿Ï‡Ï‰ÏÎ¬ ÏƒÎµ: {len(outcome['progresses_to'])} ÎµÏ€ÏŒÎ¼ÎµÎ½Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±\n"
        
        if curriculum_data.get('assessment_strategies'):
            formatted += "\n" + "=" * 80 + "\n"
            formatted += "Î£Î¤Î¡Î‘Î¤Î—Î“Î™ÎšÎ•Î£ Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î—Î£ ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ:\n"
            formatted += "=" * 80 + "\n"
            for i, strategy in enumerate(curriculum_data['assessment_strategies'], 1):
                formatted += f"\n{i}. {strategy['greek_term']}\n"
                if strategy['type']:
                    formatted += f"   Î¤ÏÏ€Î¿Ï‚: {strategy['type']}\n"
                if strategy['complexity_level']:
                    formatted += f"   Î•Ï€Î¯Ï€ÎµÎ´Î¿ Î Î¿Î»Ï…Ï€Î»Î¿ÎºÏŒÏ„Î·Ï„Î±Ï‚: {strategy['complexity_level']}\n"
                if strategy['assessment_progression']:
                    formatted += f"   Î ÏÏŒÎ¿Î´Î¿Ï‚ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ·Ï‚: {strategy['assessment_progression']}\n"
                if strategy['progression_notes']:
                    formatted += f"   Î£Î·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚: {strategy['progression_notes']}\n"
        
        if curriculum_data.get('teaching_strategies'):
            formatted += "\n" + "=" * 80 + "\n"
            formatted += "Î£Î¤Î¡Î‘Î¤Î—Î“Î™ÎšÎ•Î£ Î”Î™Î”Î‘Î£ÎšÎ‘Î›Î™Î‘Î£ ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ:\n"
            formatted += "=" * 80 + "\n"
            for i, strategy in enumerate(curriculum_data['teaching_strategies'], 1):
                formatted += f"\n{i}. {strategy['name']}\n"
                if strategy['scaffolding_type']:
                    formatted += f"   Î¤ÏÏ€Î¿Ï‚ Î¥Ï€Î¿ÏƒÏ„Î®ÏÎ¹Î¾Î·Ï‚: {strategy['scaffolding_type']}\n"
                if strategy['teaching_stage']:
                    formatted += f"   Î£Ï„Î¬Î´Î¹Î¿ Î”Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±Ï‚: {strategy['teaching_stage']}\n"
                if strategy['progression_notes']:
                    formatted += f"   Î£Î·Î¼ÎµÎ¹ÏÏƒÎµÎ¹Ï‚: {strategy['progression_notes']}\n"
        
        return formatted
    
    def _analyze_contradictions_with_progression(self, curricula_data: Dict, relationships: Dict, provider: LLMProvider, all_actual_names: Dict) -> Dict[str, Any]:
        """Analyze contradictions WITH PROGRESSION CONTEXT and HIERARCHICAL STRUCTURE"""
        
        names_list = "\n\nâš ï¸âš ï¸âš ï¸ Î”Î™Î‘Î˜Î•Î£Î™ÎœÎ‘ Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ‘ ÎŸÎÎŸÎœÎ‘Î¤Î‘ âš ï¸âš ï¸âš ï¸\n"
        for curriculum, names in all_actual_names.items():
            names_list += f"\n{curriculum}:\n"
            names_list += f"  Î•Î½ÏŒÏ„Î·Ï„ÎµÏ‚: {', '.join(names['modules'][:15])}\n"
            if names['outcomes']:
                names_list += f"  Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±: {', '.join([o[:50] for o in names['outcomes'][:5]])}\n"
        
        formatted_analysis = "Î‘ÎÎ‘Î›Î¥Î£Î— Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î©Î ÎœÎ• Î Î¡ÎŸÎŸÎ”ÎŸ ÎšÎ‘Î™ Î™Î•Î¡Î‘Î¡Î§Î™ÎšÎ— Î”ÎŸÎœÎ—:\n\n"
        
        for name, data in curricula_data.items():
            rel = relationships[name]
            formatted_analysis += f"{'=' * 80}\n"
            formatted_analysis += f"=== {name} ===\n"
            formatted_analysis += f"{'=' * 80}\n"
            formatted_analysis += f"Î˜ÎµÎ¼Î±Ï„Î¹ÎºÎ® Î ÎµÏÎ¹Î¿Ï‡Î®: {rel['subject_area']}\n"
            formatted_analysis += f"Î’Î±Î¸Î¼Î¯Î´ÎµÏ‚: {', '.join(rel['grade_levels'])}\n"
            formatted_analysis += f"Î¤Î¯Ï„Î»Î¿Ï‚: {data['curriculum_title']}\n\n"
            
            modules_structured = self._extract_module_metadata_with_structure(data['modules'])
            
            # BUILD COMPARISON TABLE
            formatted_analysis += "â”Œ" + "â”€" * 78 + "â”\n"
            formatted_analysis += "â”‚ Î£Î•Î™Î¡Î‘ Î”Î™Î”Î‘Î£ÎšÎ‘Î›Î™Î‘Î£ - Î”Î™Î‘Î’Î‘Î£Î¤Î• Î‘Î ÎŸ Î Î‘ÎÎ© Î Î¡ÎŸÎ£ Î¤Î‘ ÎšÎ‘Î¤Î©" + " " * 24 + "â”‚\n"
            formatted_analysis += "â”œ" + "â”€" * 78 + "â”¤\n"
            formatted_analysis += "â”‚ Î Î¡Î©Î¤Î— â†’ Î”Î•Î¥Î¤Î•Î¡Î— â†’ Î¤Î¡Î™Î¤Î— (Ï‡ÏÎ¿Î½Î¿Î»Î¿Î³Î¹ÎºÎ® ÏƒÎµÎ¹ÏÎ¬)" + " " * 31 + "â”‚\n"
            formatted_analysis += "â””" + "â”€" * 78 + "â”˜\n\n"
            
            for i, module in enumerate(modules_structured, 1):
                indent = "  " * (module.get('depth', 1) - 1)
                cog_level = module.get('cognitive_level', 'N/A')
                
                formatted_analysis += f"{indent}POSITION {i} (taught #{i}):\n"
                formatted_analysis += f"{indent}  Title: {module['title']}\n"
                formatted_analysis += f"{indent}  Cognitive: {cog_level}\n"
                
                if module.get('is_umbrella'):
                    formatted_analysis += f"{indent}  Type: âš ï¸ UMBRELLA\n"
                if module.get('children'):
                    formatted_analysis += f"{indent}  Type: ğŸ‘¥ PARENT\n"
                if module.get('parent'):
                    formatted_analysis += f"{indent}  Type: ğŸ“ CHILD of {module['parent']}\n"
                
                formatted_analysis += "\n"
            
            # COMPARISON TABLE
            formatted_analysis += "PROGRESSION CHECK:\n"
            formatted_analysis += "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n"
            formatted_analysis += "â”‚ ORDER   â”‚ MODULE TITLE                 â”‚ COGNITIVE    â”‚\n"
            formatted_analysis += "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n"
            
            for i, module in enumerate(modules_structured, 1):
                title_short = module['title'][:28].ljust(28)
                cog = module.get('cognitive_level', 'Unknown')[:12].ljust(12)
                formatted_analysis += f"â”‚ #{i}      â”‚ {title_short} â”‚ {cog} â”‚\n"
                
                if i < len(modules_structured):
                    next_module = modules_structured[i]
                    curr_level = {'Foundational': 1, 'Medium': 2, 'High': 3}.get(module.get('cognitive_level'), 0)
                    next_level = {'Foundational': 1, 'Medium': 2, 'High': 3}.get(next_module.get('cognitive_level'), 0)
                    
                    if curr_level < next_level:
                        arrow = "â†— INCREASE"
                    elif curr_level == next_level:
                        arrow = "â†’ SAME"
                    else:
                        arrow = "â†˜ DECREASE"
                    
                    formatted_analysis += f"â”‚         â”‚ {arrow.ljust(28)} â”‚              â”‚\n"
            
            formatted_analysis += "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n\n"
            
            # EXPLICIT FLOW
            cognitive_levels = []
            for m in modules_structured:
                cog = m.get('cognitive_level', 'Unknown')
                level_num = {'Foundational': '1', 'Medium': '2', 'High': '3'}.get(cog, '?')
                cognitive_levels.append(f"{cog}({level_num})")
            
            formatted_analysis += f"COGNITIVE FLOW: {' â†’ '.join(cognitive_levels)}\n"
            formatted_analysis += "=" * 80 + "\n\n"
        
        prompt = f"""{names_list}

    {formatted_analysis}

    âš ï¸âš ï¸âš ï¸ ÎšÎ¡Î™Î£Î™ÎœÎŸ: Î Î©Î£ ÎÎ‘ Î”Î™Î‘Î’Î‘Î£Î•Î¤Î• Î¤Î— Î£Î•Î™Î¡Î‘ âš ï¸âš ï¸âš ï¸

    Î— ÏƒÎµÎ¹ÏÎ¬ Î´Î¹Î´Î±ÏƒÎºÎ±Î»Î¯Î±Ï‚ ÎµÎ¯Î½Î±Î¹ Î‘Î ÎŸ Î Î‘ÎÎ© Î Î¡ÎŸÎ£ Î¤Î‘ ÎšÎ‘Î¤Î© ÏƒÏ„Î¿Î½ Ï€Î¯Î½Î±ÎºÎ±:

    POSITION 1 â†’ Î´Î¹Î´Î¬ÏƒÎºÎµÏ„Î±Î¹ Î Î¡Î©Î¤Î— (Ï‡ÏÎ¿Î½Î¹ÎºÎ¬ Ï€ÏÏÏ„Î·)
    POSITION 2 â†’ Î´Î¹Î´Î¬ÏƒÎºÎµÏ„Î±Î¹ Î”Î•Î¥Î¤Î•Î¡Î— (Î¼ÎµÏ„Î¬ Ï„Î·Î½ 1)
    POSITION 3 â†’ Î´Î¹Î´Î¬ÏƒÎºÎµÏ„Î±Î¹ Î¤Î¡Î™Î¤Î— (Î¼ÎµÏ„Î¬ Ï„Î·Î½ 2)

    Î Î‘Î¡Î‘Î”Î•Î™Î“ÎœÎ‘ Î‘ÎÎ‘Î“ÎÎ©Î£Î—Î£:

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ ORDER   â”‚ MODULE TITLE                 â”‚ COGNITIVE    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ #1      â”‚ Î˜ÎµÏ‰ÏÎ·Ï„Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÎ­Î³Î³Î¹ÏƒÎ·         â”‚ Foundational â”‚ â† TAUGHT FIRST
    â”‚         â”‚ â†— INCREASE                   â”‚              â”‚
    â”‚ #2      â”‚ Î˜ÎµÎ¼Î±Ï„Î¹ÎºÎ­Ï‚ ÎµÎ½ÏŒÏ„Î·Ï„ÎµÏ‚           â”‚ Foundational â”‚ â† TAUGHT SECOND
    â”‚         â”‚ â†— INCREASE                   â”‚              â”‚
    â”‚ #3      â”‚ Î”Î¹Î´Î±ÎºÏ„Î¹ÎºÎ® Î¼ÎµÎ¸Î¿Î´Î¿Î»Î¿Î³Î¯Î±        â”‚ Medium       â”‚ â† TAUGHT THIRD
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Î‘Ï…Ï„ÏŒ ÏƒÎ·Î¼Î±Î¯Î½ÎµÎ¹:
    - #1 (Foundational) comes BEFORE #3 (Medium) chronologically
    - #2 (Foundational) comes BEFORE #3 (Medium) chronologically  
    - #3 (Medium) comes AFTER #1 and #2 chronologically

    Flow: Foundational(1) â†’ Foundational(1) â†’ Medium(2)
    Math: 1 â†’ 1 â†’ 2 = NO DECREASE = NO CONTRADICTION âœ…

    âŒ WRONG INTERPRETATION:
    "#3 (Medium) Ï€ÏÎ¿Î·Î³ÎµÎ¯Ï„Î±Î¹ #2 (Foundational)"
    NO! #3 has higher order number, so it comes LATER!

    âœ… CORRECT INTERPRETATION:
    "#2 (Foundational) Ï€ÏÎ¿Î·Î³ÎµÎ¯Ï„Î±Î¹ #3 (Medium)"
    YES! Lower order number comes first!

    RULE: Lower ORDER number = Taught EARLIER

    ÎšÎ‘ÎÎŸÎÎ‘Î£ Î“Î™Î‘ PROGRESSION_REVERSAL:

    ONLY flag if ORDER #N has HIGHER cognitive level than ORDER #(N+1):

    Example 1:
    ORDER #1: Medium (2)
    ORDER #2: Foundational (1)
    2 > 1 â†’ REVERSAL âŒ

    Example 2:
    ORDER #1: Foundational (1)
    ORDER #2: Medium (2)
    1 < 2 â†’ NO REVERSAL âœ…

    Example 3:
    ORDER #1: Foundational (1)
    ORDER #2: Foundational (1)
    ORDER #3: Medium (2)
    1 â†’ 1 â†’ 2 â†’ NO REVERSAL âœ…

    ÎœÎ‘Î˜Î—ÎœÎ‘Î¤Î™ÎšÎŸÎ£ Î•Î›Î•Î“Î§ÎŸÎ£:

    For each consecutive pair (ORDER #i, ORDER #(i+1)):
    - Get cognitive_level_i as number (Foundational=1, Medium=2, High=3)
    - Get cognitive_level_(i+1) as number
    - IF cognitive_level_i > cognitive_level_(i+1):
        â†’ FLAG as PROGRESSION_REVERSAL
    - ELSE:
        â†’ NO PROBLEM

    âŒ ÎœÎ—Î Î£Î¥Î“ÎšÎ¡Î™ÎÎ•Î¤Î•:
    - Parent Î¼Îµ Child (Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÏŒ depth)
    - Umbrella modules (âš ï¸)
    - Non-consecutive modules

    âœ… ÎœÎŸÎÎŸ Î£Î¥Î“ÎšÎ¡Î™ÎÎ•Î¤Î•:
    - ORDER #1 Î¼Îµ ORDER #2
    - ORDER #2 Î¼Îµ ORDER #3
    - Consecutive orders only

    JSON ÎœÎŸÎ¡Î¦Î—:
    {{
    "contradictions": [
        {{
        "type": "progression_reversal",
        "severity": "high",
        "description": "ORDER #X (CognitiveLevel=Y) followed by ORDER #(X+1) (CognitiveLevel=Z) where Y > Z",
        "elements": ["ORDER #X: title", "ORDER #(X+1): title"],
        "impact": "Students learn advanced before basic",
        "recommendation": "Swap order"
        }}
    ],
    "normal_progressions": [
        "List progressions that are CORRECT (increasing or same level)"
    ]
    }}

    CRITICAL: Use ORDER numbers from the table. Lower ORDER = Earlier teaching."""

        max_retries = 2
        for attempt in range(max_retries):
            try:
                response = self.llm_service.generate_with_provider(provider, prompt)
                parsed = self._parse_llm_response(response)
                
                has_valid_names = True
                for names in all_actual_names.values():
                    if not self._validate_response_names(parsed, names):
                        has_valid_names = False
                        break
                
                if has_valid_names or attempt == max_retries - 1:
                    if not has_valid_names:
                        parsed['validation_warning'] = "Response contains generic placeholders"
                    return parsed
                
                logger.warning(f"Validation failed on attempt {attempt + 1}")
                time.sleep(1)
                
            except Exception as e:
                logger.error(f"Analysis failed on attempt {attempt + 1}: {e}")
                if attempt == max_retries - 1:
                    return {'error': str(e), 'contradictions': []}
        
        return {'error': 'All validation attempts failed', 'contradictions': []}
    def _is_language_related_subject(self, subject_area: str, title: str) -> bool:
        """Determine if subjects are language-related"""
        language_indicators = [
            'Î³Î»ÏÏƒÏƒÎ±', 'Î»Î¿Î³Î¿Ï„ÎµÏ‡Î½Î¯Î±', 'language', 'literature', 
            'ÎµÎ»Î»Î·Î½Î¹Îº', 'greek', 'Ï†Î¹Î»Î¿Î»Î¿Î³', 'ÎºÎµÎ¯Î¼ÎµÎ½'
        ]
        
        text_to_check = f"{subject_area} {title}".lower()
        return any(indicator in text_to_check for indicator in language_indicators)
    
    def _infer_subject_area(self, title: str) -> str:
        """Infer subject area from curriculum title"""
        if not title:
            return 'general'
            
        title_lower = title.lower()
        
        if any(term in title_lower for term in ['Î³Î»ÏÏƒÏƒÎ±', 'language', 'Î³Î»Ï‰ÏƒÏƒ']):
            return 'greek_language'
        elif any(term in title_lower for term in ['Î»Î¿Î³Î¿Ï„ÎµÏ‡Î½Î¯Î±', 'literature', 'Î»Î¿Î³Î¿Ï„ÎµÏ‡Î½']):
            return 'literature'
        elif any(term in title_lower for term in ['Î¼Î±Î¸Î·Î¼Î±Ï„Î¹Îº', 'mathematics', 'math']):
            return 'mathematics'
        elif any(term in title_lower for term in ['Î¹ÏƒÏ„Î¿ÏÎ¯', 'history', 'hist']):
            return 'history'
        elif any(term in title_lower for term in ['Ï†Ï…ÏƒÎ¹Îº', 'physics', 'science']):
            return 'science'
        else:
            return 'general'
    
    def _get_all_topic_descriptions(self, g: Graph, module_uri: URIRef) -> List[str]:
        """Get all topic descriptions for a module"""
        topics = []
        
        for _, _, topic_uri in g.triples((module_uri, CURRKG.coversTopic, None)):
            topic_desc = self._get_property_value(g, topic_uri, "hasDescription")
            if not topic_desc:
                topic_desc = self._get_property_value(g, topic_uri, "asString")
            if topic_desc:
                topics.append(topic_desc)
        
        return topics
    
    def _get_property_value(self, g: Graph, subject: URIRef, property_name: str) -> str:
        """Get single property value from multiple possible namespaces"""
        # Try CURRKG namespace first
        prop_uri = URIRef(f"http://curriculum-kg.org/ontology/{property_name}")
        for _, _, obj in g.triples((subject, prop_uri, None)):
            return str(obj)
        
        # Try CURRICULUM namespace as fallback
        prop_uri = URIRef(f"http://curriculum.edu.gr/2022/{property_name}")
        for _, _, obj in g.triples((subject, prop_uri, None)):
            return str(obj)
        
        return ""

    def _get_all_property_values(self, g: Graph, subject: URIRef, property_name: str) -> List[str]:
        """Get all values for a property"""
        values = []
        
        prop_uri = URIRef(f"http://curriculum-kg.org/ontology/{property_name}")
        for _, _, obj in g.triples((subject, prop_uri, None)):
            values.append(str(obj))
        
        prop_uri = URIRef(f"http://curriculum.edu.gr/2022/{property_name}")
        for _, _, obj in g.triples((subject, prop_uri, None)):
            values.append(str(obj))
        
        return values
    
    def _parse_llm_response(self, response: str) -> Dict[str, Any]:
        """Improved LLM response parser with multiple fallback strategies"""
        if not response or not response.strip():
            raise ValueError("Empty response from LLM")
        
        # Try multiple regex patterns
        json_patterns = [
            r'\{(?:[^{}]|\{(?:[^{}]|\{[^{}]*\})*\})*\}',  # Balanced braces
            r'\{.*\}',  # Simple greedy
        ]
        
        for i, pattern in enumerate(json_patterns, 1):
            matches = re.findall(pattern, response, re.DOTALL)
            for match in matches:
                try:
                    cleaned_match = match.strip()
                    parsed = json.loads(cleaned_match)
                    logger.info(f"Successfully parsed JSON using pattern {i}")
                    return parsed
                except json.JSONDecodeError:
                    continue
        
        # Brace extraction
        first_brace = response.find('{')
        last_brace = response.rfind('}')
        
        if first_brace != -1 and last_brace != -1 and last_brace > first_brace:
            potential_json = response[first_brace:last_brace + 1]
            try:
                return json.loads(potential_json)
            except json.JSONDecodeError:
                pass
        
        # Fallback
        logger.error(f"JSON parsing failed. Response: {response[:200]}...")
        return {
            "contradictions": [],
            "analysis": "JSON parsing failed - malformed response", 
            "raw_response": response[:500],
            "parsing_error": True
        }
    
    def generate_contradiction_report(self, 
                                    internal_results: Dict[str, Any],
                                    cross_results: Dict[str, Any],
                                    progression_results: Dict[str, Any],
                                    provider: LLMProvider) -> str:
        """Generate comprehensive report WITH PROGRESSION ANALYSIS"""
        
        prompt = f"""Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î· Î±Î½Î±Ï†Î¿ÏÎ¬ Î±Î½Ï„Î¹Ï†Î¬ÏƒÎµÏ‰Î½ ÎœÎ• Î‘ÎÎ‘Î›Î¥Î£Î— Î Î¡ÎŸÎŸÎ”ÎŸÎ¥:

Î•Î£Î©Î¤Î•Î¡Î™ÎšÎ•Î£ Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î™Î£:
{json.dumps(internal_results, ensure_ascii=False, indent=2)}

Î”Î™Î‘Î Î¡ÎŸÎ“Î¡Î‘ÎœÎœÎ‘Î¤Î™ÎšÎ•Î£ Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î™Î£:
{json.dumps(cross_results, ensure_ascii=False, indent=2)}

Î‘ÎÎ‘Î›Î¥Î£Î— Î Î¡ÎŸÎŸÎ”ÎŸÎ¥:
{json.dumps(progression_results, ensure_ascii=False, indent=2)}

Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î®ÏƒÏ„Îµ Î´Î¿Î¼Î·Î¼Î­Î½Î· Î±Î½Î±Ï†Î¿ÏÎ¬:

1. Î•ÎšÎ¤Î•Î›Î•Î£Î¤Î™ÎšÎ— Î Î•Î¡Î™Î›Î—Î¨Î—
   - Î£Ï…Î½Î¿Î»Î¹ÎºÎ® ÎµÎºÏ„Î¯Î¼Î·ÏƒÎ· Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚
   - Î Î¿Î¹ÏŒÏ„Î·Ï„Î± Ï€ÏÎ¿ÏŒÎ´Î¿Ï… Î¼Î¬Î¸Î·ÏƒÎ·Ï‚
   - ÎšÏÎ¯ÏƒÎ¹Î¼Î± Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±

2. Î‘ÎÎ‘Î›Î¥Î£Î— Î Î¡ÎŸÎŸÎ”ÎŸÎ¥
   - Î ÏŒÏƒÎ¿ ÎºÎ±Î»Î¬ Ï€ÏÎ¿Î¿Î´ÎµÏÎ¿Ï…Î½ Î¿Î¹ Î¼Î±Î¸Î·Ï„Î­Ï‚
   - Î›Î¿Î³Î¹ÎºÎ® ÏÎ¿Î® Î¼Î¬Î¸Î·ÏƒÎ·Ï‚
   - Î ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î± ÏƒÏ„Î·Î½ ÎµÎ¾Î­Î»Î¹Î¾Î· Î´Ï…ÏƒÎºÎ¿Î»Î¯Î±Ï‚

3. Î Î¡Î‘Î“ÎœÎ‘Î¤Î™ÎšÎ•Î£ Î‘ÎÎ¤Î™Î¦Î‘Î£Î•Î™Î£
   - ÎœÏŒÎ½Î¿ ÏƒÎ¿Î²Î±ÏÎ¬ Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±
   - Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î± Ï€Î±ÏÎ±Î´ÎµÎ¯Î³Î¼Î±Ï„Î±
   - Î•Ï€Î¯Ï€Ï„Ï‰ÏƒÎ· ÏƒÏ„Î· Î¼Î¬Î¸Î·ÏƒÎ·

4. Î˜Î•Î¤Î™ÎšÎ‘ Î£Î¤ÎŸÎ™Î§Î•Î™Î‘
   - ÎšÎ±Î»Î¬ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼Î­Î½ÎµÏ‚ Ï€ÏÎ¿ÏŒÎ´Î¿Ï…Ï‚
   - Î£Ï…Î½Î­ÏÎ³Î¹ÎµÏ‚ Î¼ÎµÏ„Î±Î¾Ï Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î¬Ï„Ï‰Î½

5. Î£Î¥Î£Î¤Î‘Î£Î•Î™Î£
   - Î ÏÎ¿Ï„ÎµÏÎ±Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î´ÏÎ¬ÏƒÎ·Ï‚
   - Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½ÎµÏ‚ Î²ÎµÎ»Ï„Î¹ÏÏƒÎµÎ¹Ï‚

Î¤Î¿Î½Î¯ÏƒÏ„Îµ Ï„Î± Î¸ÎµÏ„Î¹ÎºÎ¬ Ï€ÏÎ¹Î½ Î±Ï€ÏŒ Ï„Î± Ï€ÏÎ¿Î²Î»Î®Î¼Î±Ï„Î±."""

        try:
            return self.llm_service.generate_with_provider(provider, prompt)
        except Exception as e:
            logger.error(f"Report generation failed: {e}")
            return f"Î‘Ï€Î¿Ï„Ï…Ï‡Î¯Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î±Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬Ï‚: {str(e)}"