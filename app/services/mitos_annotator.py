# app/services/mitos_annotator.py
"""
MITOS Stage 2: Legal Text Annotation Service
Following TOGAF Core Metamodel approach from research paper
"""

import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path

from app.services.llm_service import MultiLLMService, LLMProvider

logger = logging.getLogger(__name__)

class AnnotationPerspective(Enum):
    CITIZEN = "citizen"
    OFFICIAL = "official"
    EXPERT = "expert"

@dataclass
class TOGAFAnnotation:
    """TOGAF Core Metamodel annotation structure"""
    processes: List[str]
    functions: List[str]
    actors: List[str]
    roles: List[str]
    organization_units: List[str]
    events: List[str]
    products: List[str]
    controls: List[str]
    business_services: List[str]

@dataclass
class PerspectiveAnnotation:
    """Perspective-specific annotation"""
    perspective: AnnotationPerspective
    questions: List[str]
    answers: List[str]
    key_requirements: List[str]
    process_steps: List[str]
    required_documents: List[str]

@dataclass
class AnnotatedLegalText:
    """Complete annotation result"""
    original_text: str
    text_title: str
    text_type: str
    togaf_annotation: TOGAFAnnotation
    citizen_perspective: PerspectiveAnnotation
    official_perspective: PerspectiveAnnotation
    confidence_score: float

class MITOSTextAnnotator:
    """MITOS Stage 2: Automated legal text annotation using TOGAF metamodel"""
    
    def __init__(self):
        self.llm_service = MultiLLMService()
        
    def setup_llm(self, provider: LLMProvider, api_key: str, model_name: Optional[str] = None):
        """Setup LLM provider"""
        self.llm_service.add_service(provider, api_key, model_name)
        
    def annotate_legal_text(self, 
                          text: str, 
                          text_title: str,
                          text_type: str,
                          provider: LLMProvider) -> AnnotatedLegalText:
        """
        Annotate legal text using TOGAF metamodel and multiple perspectives
        """
        logger.info(f"Starting MITOS Stage 2 annotation for: {text_title}")
        
        # Step 1: TOGAF Core Metamodel annotation
        togaf_annotation = self._extract_togaf_elements(text, text_title, provider)
        
        # Step 2: Multi-perspective annotation
        citizen_perspective = self._annotate_citizen_perspective(text, text_title, provider)
        official_perspective = self._annotate_official_perspective(text, text_title, provider)
        
        # Step 3: Calculate confidence score
        confidence = self._calculate_confidence_score(togaf_annotation, [citizen_perspective, official_perspective])
        
        return AnnotatedLegalText(
            original_text=text,
            text_title=text_title,
            text_type=text_type,
            togaf_annotation=togaf_annotation,
            citizen_perspective=citizen_perspective,
            official_perspective=official_perspective,
            confidence_score=confidence
        )
    
    def _extract_togaf_elements(self, text: str, title: str, provider: LLMProvider) -> TOGAFAnnotation:
        """Extract TOGAF Core Metamodel elements from legal text"""
        
        prompt = f"""Analyze the following Greek legal text and extract TOGAF Core Metamodel elements.

LEGAL TEXT TITLE: {title}
LEGAL TEXT: {text[:3000]}...

Extract the following elements and return as JSON:

1. PROCESSES: Administrative processes described in the text
2. FUNCTIONS: Business functions realized by the processes  
3. ACTORS: People or entities participating (students, parents, teachers, officials)
4. ROLES: Specific roles assumed by actors (student guardian, head teacher, director)
5. ORGANIZATION_UNITS: Organizational units involved (schools, directorates, ministries)
6. EVENTS: Events generated by processes (enrollment, submission, approval)
7. PRODUCTS: Outputs produced (certificates, lists, decisions)
8. CONTROLS: Controls and validations in the process
9. BUSINESS_SERVICES: Public services realized

Return ONLY valid JSON in this format:
{{
    "processes": ["process1", "process2"],
    "functions": ["function1", "function2"],
    "actors": ["actor1", "actor2"],
    "roles": ["role1", "role2"],
    "organization_units": ["unit1", "unit2"],
    "events": ["event1", "event2"],
    "products": ["product1", "product2"],
    "controls": ["control1", "control2"],
    "business_services": ["service1", "service2"]
}}

CRITICAL: Return ONLY the JSON structure, no explanations."""

        try:
            response = self.llm_service.generate_with_provider(provider, prompt)
            data = self._parse_json_response(response)
            
            return TOGAFAnnotation(
                processes=data.get('processes', []),
                functions=data.get('functions', []),
                actors=data.get('actors', []),
                roles=data.get('roles', []),
                organization_units=data.get('organization_units', []),
                events=data.get('events', []),
                products=data.get('products', []),
                controls=data.get('controls', []),
                business_services=data.get('business_services', [])
            )
        except Exception as e:
            logger.error(f"TOGAF annotation failed: {e}")
            return TOGAFAnnotation([], [], [], [], [], [], [], [], [])
    
    def _annotate_citizen_perspective(self, text: str, title: str, provider: LLMProvider) -> PerspectiveAnnotation:
        """Annotate from citizen/parent perspective"""
        
        prompt = f"""Analyze this Greek legal text from a CITIZEN/PARENT perspective who needs to use this administrative process.

LEGAL TEXT: {title}
TEXT CONTENT: {text[:2000]}...

Answer these questions from a citizen's viewpoint and return as JSON:

1. QUESTIONS: What would citizens ask about this process?
2. ANSWERS: Clear answers to those questions
3. KEY_REQUIREMENTS: What do citizens need to know/do?
4. PROCESS_STEPS: Step-by-step actions citizens must take
5. REQUIRED_DOCUMENTS: Documents citizens must provide

Return ONLY valid JSON:
{{
    "questions": ["What documents do I need?", "Where do I submit?"],
    "answers": ["Answer 1", "Answer 2"],
    "key_requirements": ["Requirement 1", "Requirement 2"],
    "process_steps": ["Step 1: Do this", "Step 2: Do that"],
    "required_documents": ["Document 1", "Document 2"]
}}

Focus on practical, actionable information citizens need."""

        try:
            response = self.llm_service.generate_with_provider(provider, prompt)
            data = self._parse_json_response(response)
            
            return PerspectiveAnnotation(
                perspective=AnnotationPerspective.CITIZEN,
                questions=data.get('questions', []),
                answers=data.get('answers', []),
                key_requirements=data.get('key_requirements', []),
                process_steps=data.get('process_steps', []),
                required_documents=data.get('required_documents', [])
            )
        except Exception as e:
            logger.error(f"Citizen perspective annotation failed: {e}")
            return PerspectiveAnnotation(AnnotationPerspective.CITIZEN, [], [], [], [], [])
    
    def _annotate_official_perspective(self, text: str, title: str, provider: LLMProvider) -> PerspectiveAnnotation:
        """Annotate from public official perspective"""
        
        prompt = f"""Analyze this Greek legal text from a PUBLIC OFFICIAL perspective who must implement this administrative process.

LEGAL TEXT: {title}
TEXT CONTENT: {text[:2000]}...

Answer these questions from an official's viewpoint and return as JSON:

1. QUESTIONS: What would officials need to know to implement this?
2. ANSWERS: Implementation guidance and procedures
3. KEY_REQUIREMENTS: Legal obligations and compliance requirements
4. PROCESS_STEPS: Internal administrative steps officials must follow
5. REQUIRED_DOCUMENTS: Forms and documents officials must handle/process

Return ONLY valid JSON:
{{
    "questions": ["How do I process applications?", "What validations are required?"],
    "answers": ["Answer 1", "Answer 2"],
    "key_requirements": ["Legal requirement 1", "Compliance requirement 2"],
    "process_steps": ["Step 1: Process application", "Step 2: Validate documents"],
    "required_documents": ["Internal form 1", "Validation document 2"]
}}

Focus on legal compliance, procedures, and administrative actions."""

        try:
            response = self.llm_service.generate_with_provider(provider, prompt)
            data = self._parse_json_response(response)
            
            return PerspectiveAnnotation(
                perspective=AnnotationPerspective.OFFICIAL,
                questions=data.get('questions', []),
                answers=data.get('answers', []),
                key_requirements=data.get('key_requirements', []),
                process_steps=data.get('process_steps', []),
                required_documents=data.get('required_documents', [])
            )
        except Exception as e:
            logger.error(f"Official perspective annotation failed: {e}")
            return PerspectiveAnnotation(AnnotationPerspective.OFFICIAL, [], [], [], [], [])
    
    def _calculate_confidence_score(self, togaf: TOGAFAnnotation, perspectives: List[PerspectiveAnnotation]) -> float:
        """Calculate confidence score for annotation quality"""
        score = 0.0
        
        # TOGAF completeness (40% of score)
        togaf_fields = [togaf.processes, togaf.functions, togaf.actors, togaf.roles, 
                       togaf.organization_units, togaf.events, togaf.products, togaf.controls, togaf.business_services]
        filled_fields = sum(1 for field in togaf_fields if field)
        togaf_completeness = filled_fields / len(togaf_fields)
        score += togaf_completeness * 0.4
        
        # Perspective completeness (60% of score)
        perspective_completeness = 0.0
        for perspective in perspectives:
            fields = [perspective.questions, perspective.answers, perspective.key_requirements,
                     perspective.process_steps, perspective.required_documents]
            filled = sum(1 for field in fields if field)
            perspective_completeness += (filled / len(fields))
        
        if perspectives:
            perspective_completeness /= len(perspectives)
            score += perspective_completeness * 0.6
        
        return min(1.0, score)
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """Parse LLM JSON response with error handling"""
        if not response or not response.strip():
            return {}
        
        try:
            # Clean the response
            cleaned = response.strip()
            
            # Remove markdown formatting
            if cleaned.startswith("```json"):
                cleaned = cleaned.replace("```json", "").replace("```", "").strip()
            elif cleaned.startswith("```"):
                lines = cleaned.split('\n')
                if len(lines) > 2:
                    cleaned = '\n'.join(lines[1:-1])
            
            # Try to find JSON within the response
            import re
            json_match = re.search(r'(\{.*\})', cleaned, re.DOTALL)
            if json_match:
                cleaned = json_match.group(1)
            
            return json.loads(cleaned)
            
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse JSON response: {e}")
            logger.error(f"Response was: {response[:200]}...")
            return {}
        except Exception as e:
            logger.error(f"Unexpected error parsing response: {e}")
            return {}
    
    def save_annotation(self, annotation: AnnotatedLegalText, output_path: Path):
        """Save annotation result to JSON file"""
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # Convert dataclass to dict for JSON serialization with enum handling
        def convert_to_serializable(obj):
            if isinstance(obj, dict):
                return {k: convert_to_serializable(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_to_serializable(item) for item in obj]
            elif isinstance(obj, AnnotationPerspective):
                return obj.value  # Convert enum to its string value
            else:
                return obj
        
        annotation_dict = {
            "text_title": annotation.text_title,
            "text_type": annotation.text_type,
            "confidence_score": annotation.confidence_score,
            "togaf_annotation": convert_to_serializable(asdict(annotation.togaf_annotation)),
            "citizen_perspective": convert_to_serializable(asdict(annotation.citizen_perspective)),
            "official_perspective": convert_to_serializable(asdict(annotation.official_perspective)),
            "original_text_length": len(annotation.original_text),
            "annotation_timestamp": str(datetime.now())
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(annotation_dict, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Annotation saved to {output_path}")